{"paragraphs":[{"text":"%md\n# Tutorial 4b: Extending your analysis with more datasets\n\nThis tutorial was built for BDCS-CE version 17.4.1 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n    Be sure you previously ran the Tutorial: \"Working with the Spark Interpreter\"\n\nThis tutorial will add some additional datasets (weather and holidays) to combine with our bike trip data.\n\n## Contents\n\n+ How to get daily weather data from the US Government\n+ Creating a temporary table on weather data\n+ Creating a temporary table on calendar/holiday data\n+ Joining our bike_trips with weather and calendar data\n+ Creating a permanent hive parquet table on the combined data\n\nAs a reminder, the documentation for BDCS-CE can be found: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\" target=\"_blank\">here</a>","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tutorial 4b: Extending your analysis with more datasets</h1>\n<p>This tutorial was built for BDCS-CE version 17.4.1 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#x64;&#97;&#118;i&#x64;&#46;b&#x61;&#x79;a&#114;&#100;&#64;o&#114;&#x61;c&#x6c;&#x65;.co&#x6d;\">&#x64;&#97;&#118;i&#x64;&#46;b&#x61;&#x79;a&#114;&#100;&#64;o&#114;&#x61;c&#x6c;&#x65;.co&#x6d;</a></p>\n<pre><code>Be sure you previously ran the Tutorial: &quot;Working with the Spark Interpreter&quot;\n</code></pre>\n<p>This tutorial will add some additional datasets (weather and holidays) to combine with our bike trip data.</p>\n<h2>Contents</h2>\n<ul>\n  <li>How to get daily weather data from the US Government</li>\n  <li>Creating a temporary table on weather data</li>\n  <li>Creating a temporary table on calendar/holiday data</li>\n  <li>Joining our bike_trips with weather and calendar data</li>\n  <li>Creating a permanent hive parquet table on the combined data</li>\n</ul>\n<p>As a reminder, the documentation for BDCS-CE can be found: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\" target=\"_blank\">here</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275485_86425551","id":"20170414-131903_889251720","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1790"},{"text":"%md\n# Requesting free Weather Data from the Government\n\nIn this tutorial, we will add some weather data to our data lake.  We will use the US Government's National Center for Environmental Information website to request the daily weather summary for New York City for December 2016 (the same time frame as our bike data).  We will use the website to request/order the weather data and then we download the data once the request is ready.\n\n![CDO](https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/snap0012665.jpg)\n\n\nTo get our weather data, follow these steps: (if you are in a hurry, you can skip below to the paragraph titled \"If you are in a hurry...\")\n\n+ Open a browser to the Climate Data Online website, run by the US Government: <a href=\"https://www.ncdc.noaa.gov/cdo-web/\" target=\"_blank\">https ://www.ncdc.noaa.gov/cdo-web/</a>\n+ Click on Search Tool\n+ Choose:\nDaily Summaries\n2016-12-01 to 2016-12-31\nCites\nNew York City\n+ Click the \"ADD TO CART\" button for the \"New York, NY US\" row.\n+ Navigate to the \"Cart (Free Data) 1 item\" area and click \"View All Items(1)\"\n+ Choose Custom GHCN-Daily CSV and click Continue\n+ In the \"Select data types for custom output\" section, click \"Show All\".  Then select\nPRCP - Precipitation\nSNWD - Snow depth \nSNOW - Snowfall\nTAVG - Average Temperature.\nTMAX - Maximum temperature\nTMIN - Minimum temperature\nAWND - Average wind speed\n+ Click Continue\n+ Enter your email address and click Submit Order\n\n![CDO2](https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/WeatherOrder.gif)\n\nGood job!  Now get yourself a cup a coffee as it may take a few minutes for your order to work through the queue.\n\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Requesting free Weather Data from the Government</h1>\n<p>In this tutorial, we will add some weather data to our data lake. We will use the US Government&rsquo;s National Center for Environmental Information website to request the daily weather summary for New York City for December 2016 (the same time frame as our bike data). We will use the website to request/order the weather data and then we download the data once the request is ready.</p>\n<p><img src=\"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/snap0012665.jpg\" alt=\"CDO\" /></p>\n<p>To get our weather data, follow these steps: (if you are in a hurry, you can skip below to the paragraph titled &ldquo;If you are in a hurry&hellip;&rdquo;)</p>\n<ul>\n  <li>Open a browser to the Climate Data Online website, run by the US Government: <a href=\"https://www.ncdc.noaa.gov/cdo-web/\" target=\"_blank\">https ://www.ncdc.noaa.gov/cdo-web/</a></li>\n  <li>Click on Search Tool</li>\n  <li>Choose:<br/>Daily Summaries<br/>2016-12-01 to 2016-12-31<br/>Cites<br/>New York City</li>\n  <li>Click the &ldquo;ADD TO CART&rdquo; button for the &ldquo;New York, NY US&rdquo; row.</li>\n  <li>Navigate to the &ldquo;Cart (Free Data) 1 item&rdquo; area and click &ldquo;View All Items(1)&rdquo;</li>\n  <li>Choose Custom GHCN-Daily CSV and click Continue</li>\n  <li>In the &ldquo;Select data types for custom output&rdquo; section, click &ldquo;Show All&rdquo;. Then select<br/>PRCP - Precipitation<br/>SNWD - Snow depth<br/>SNOW - Snowfall<br/>TAVG - Average Temperature.<br/>TMAX - Maximum temperature<br/>TMIN - Minimum temperature<br/>AWND - Average wind speed</li>\n  <li>Click Continue</li>\n  <li>Enter your email address and click Submit Order</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/WeatherOrder.gif\" alt=\"CDO2\" /></p>\n<p>Good job! Now get yourself a cup a coffee as it may take a few minutes for your order to work through the queue.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275485_86425551","id":"20170616-103849_1176559517","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1791"},{"text":"%md\n# Downloading, Uploading the weather data when the request is ready\n\nA few minutes after submiting your free order for weather data, you should receive an email indicating that your Order is complete.\n\n+ Click on the Order ID link in the email.  This will take you to the Order History page\n+ Right-click on the download button and choose Copy Link Location\n+ Paste the value into the weather data URL input field in the paragraph below, then run the paragraph below\n\n![CDODownload](https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/WeatherDownload.gif)\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Downloading, Uploading the weather data when the request is ready</h1>\n<p>A few minutes after submiting your free order for weather data, you should receive an email indicating that your Order is complete.</p>\n<ul>\n  <li>Click on the Order ID link in the email. This will take you to the Order History page</li>\n  <li>Right-click on the download button and choose Copy Link Location</li>\n  <li>Paste the value into the weather data URL input field in the paragraph below, then run the paragraph below</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/WeatherDownload.gif\" alt=\"CDODownload\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275485_86425551","id":"20171006-124543_574686421","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1792"},{"text":"%md\n## If you are in a hurry... (and don't want to order the government weather data yourself)\n\nCopy this value and paste it into the Weather_Data_URL input field below and run the paragraph.\n\n    https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/files/1090166.csv\n    \n\n\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>If you are in a hurry&hellip; (and don&rsquo;t want to order the government weather data yourself)</h2>\n<p>Copy this value and paste it into the Weather_Data_URL input field below and run the paragraph.</p>\n<pre><code>https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/files/1090166.csv\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275486_87579798","id":"20171006-125236_974558193","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1793"},{"title":"Script to download weather data and upload to Object Store","text":"%sh\nCONTAINER=journeyC\nDIRECTORY=weather\nFILENAME=201612-weather\n\nexport HADOOP_ROOT_LOGGER=WARN\n\ntest -e $DIRECTORY || mkdir $DIRECTORY\ncd $DIRECTORY\nrm $FILENAME.csv\n\necho \"Downloading $FILENAME.csv.  This may take a minute.\"\nwget -O $FILENAME.csv ${Weather_Data_URL=https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/files/1090166.csv}\necho \".\"\necho \".\"\necho \".\"\nls -ltr $FILENAME.csv\necho \".\"\necho \".\"\necho \".\"\n\necho \"Storing file to Object Storage.  This may take a few minutes.\"\n# we use the hadoop swift:// driver to interact with the Object Store.\n# The .default configuration of the swift driver is the object store connection you defined when you created the BDCSCE instance.\n\necho \"List the directory. directory should be empty or missing\"\nhadoop fs -ls oci://test01bdc01@orasejapan/$DIRECTORY \necho \"Make the raw directory in Object Store\"\nhadoop fs -mkdir -p oci://test01bdc01@orasejapan/$DIRECTORY/raw \necho \"Copy First File to Object Store. May take a minute\"\nhadoop fs -put $FILENAME.csv oci://test01bdc01@orasejapan/$DIRECTORY/raw/$FILENAME.csv \necho \"Validate by listing the csv file that got copied to Object Store\"\nhadoop fs -ls oci://test01bdc01@orasejapan/$DIRECTORY/raw \necho \".\"\necho \".\"\n\necho \"Quick glance at first few lines of weather file...\"\nhead $FILENAME.csv\necho \".\"\necho \".\"\necho \"done\"","dateUpdated":"2018-03-07T02:56:44+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":243.15,"optionOpen":false}}},"enabled":true},"settings":{"params":{"Weather_Data_URL":"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/files/1090166.csv"},"forms":{"Weather_Data_URL":{"name":"Weather_Data_URL","defaultValue":"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/files/1090166.csv","hidden":false,"$$hashKey":"object:3134"}}},"apps":[],"jobName":"paragraph_1520365275486_87579798","id":"20171006-125424_1155428025","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1794","user":"anonymous","dateFinished":"2018-03-07T02:54:34+0000","dateStarted":"2018-03-07T02:54:16+0000"},{"text":"%md\n## Reading the weather data and registering as a Spark SQL table\n\nThe next step is to use Spark to read our weather data CSV file that we uploaded to the Object Store.  Once we read the CSV into a Spark Data Frame, we will register the data frame as a Spark SQL temp table.\n\nYou can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html\" target=\"_blank\">Spark SQL Programming Guide</a>\n\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Reading the weather data and registering as a Spark SQL table</h2>\n<p>The next step is to use Spark to read our weather data CSV file that we uploaded to the Object Store. Once we read the CSV into a Spark Data Frame, we will register the data frame as a Spark SQL temp table.</p>\n<p>You can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html\" target=\"_blank\">Spark SQL Programming Guide</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275486_87579798","id":"20170417-090240_1793194469","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1795"},{"title":"Spark Scala to read CSV and register as a temp view","text":"%spark\n\n\nval Container = \"journeyC\"\nval Directory = \"weather\"\n\nsqlContext.setConf(\"spark.sql.shuffle.partitions\", \"4\")\n\nvar wdf: org.apache.spark.sql.DataFrame = null\n\nif( \"oci://test01bdc01@orasejapan\".contains(\"swift\")  ){\n         println(\"Running on OCI-C\");\n   //We will use the bdfs (alluxio) cached file system to access our object store data...\n   wdf = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(\"bdfs://localhost:19998/\"+Directory+\"/raw/201612-weather.csv\")\n} else {\n         println(\"Running on OCI\");\n   wdf = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"oci://test01bdc01@orasejapan/\"+Directory+\"/raw/201612-weather.csv\")\n}\n\n// If you get this error message:\n// java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n// Then go to the Settings tab, then click on Notebook.  Then restart the Notebook.  This will restart your SparkContext\n\n\nprintln(\"Here is the schema detected from the CSV\")\nwdf.printSchema()\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  wdf.count() \n)) \nprintln(\"..\")\n\nwdf.createOrReplaceTempView(\"weather_temp\")\nprintln(\"done\")","dateUpdated":"2018-03-07T02:57:07+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":544,"optionOpen":false}}},"graph":{"mode":"table","height":247,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"container":"dcb-bdcs-apr12","CONTAINER":"citibike","FILENAME":"201612-citibike-tripdata"},"forms":{}},"apps":[],"jobName":"paragraph_1520365275487_87195049","id":"20170414-134031_1271833288","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1796","user":"anonymous","dateFinished":"2018-03-07T02:57:22+0000","dateStarted":"2018-03-07T02:57:07+0000"},{"title":"SQL to experiment with our Weather data","text":"%sql\nselect * from weather_temp\nwhere NAME like '%CENTRAL%'","dateUpdated":"2018-03-06T19:41:15+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275487_87195049","id":"20171006-132920_1541770419","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1797"},{"title":"More SQL to experiment with our Weather data","text":"%sql\nselect cast(date as date) day_of_month, tmax, tmin, prcp*20 prcp_scaled\nfrom weather_temp\nwhere station='USW00094728'\norder by day_of_month","dateUpdated":"2018-03-06T19:41:15+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false,"setting":{"lineChart":{"lineWithFocus":false}},"commonSetting":{},"keys":[{"name":"day_of_month","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"tmax","index":1,"aggr":"sum"},{"name":"tmin","index":2,"aggr":"sum"},{"name":"prcp_scaled","index":3,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275487_87195049","id":"20171006-133037_1442897346","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1798"},{"text":"%md\n# Creating a calendar dataset\n\nIn addition to weather, let's add some calendar data such as holidays and attributes about workdays and weekends.  Since there are not many holidays, it seems like overkill to create a new file and upload it just to keep track.  Instead, we'll programatically create a new holiday dataset in the next paragraph.","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Creating a calendar dataset</h1>\n<p>In addition to weather, let&rsquo;s add some calendar data such as holidays and attributes about workdays and weekends. Since there are not many holidays, it seems like overkill to create a new file and upload it just to keep track. Instead, we&rsquo;ll programatically create a new holiday dataset in the next paragraph.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275487_87195049","id":"20171006-133825_216597577","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1799"},{"title":"Create a temp view for Holidays","text":"%spark\n\n//case class Holiday(hdate: String)\n//val hdf = Seq(Holiday(\"2016-12-24\"), Holiday(\"2016-12-25\"), Holiday(\"2016-12-26\"), Holiday(\"2016-12-31\")).toDS()\nval hdf = Seq(\"2016-12-24\", \"2016-12-25\", \"2016-12-26\", \"2016-12-31\").toDS()\nhdf.show()\n\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  hdf.count() \n)) \nprintln(\"..\")\n\nhdf.createOrReplaceTempView(\"holidays_temp\")\nprintln(\"done\")\n","dateUpdated":"2018-03-07T02:58:13+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275488_72959340","id":"20170928-205441_1475760890","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1800","user":"anonymous","dateFinished":"2018-03-07T02:58:15+0000","dateStarted":"2018-03-07T02:58:13+0000"},{"title":"Basic SQL to experiment with joining Weather and Calendar","text":"%sql\nselect cast(date as date) day_of_month, tmax, tmin, h.value , \n   date_format(date,\"E\") day_of_week,\n   IF(isnull(h.value), 'N', 'Holiday') holiday,\n   IF(isnull(h.value) and date_format(date,\"E\") in (\"Mon\",'Tue','Wed','Thu','Fri'), 'Workday', 'N') workday\nfrom weather_temp w LEFT OUTER JOIN holidays_temp h\nON (w.date = h.value)\nwhere station='USW00094728'\norder by day_of_month","dateUpdated":"2018-03-06T19:41:15+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275488_72959340","id":"20171011-182405_1413556095","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1801"},{"title":"SQL to experiment with joining Weather and Calendar and Bike Trips","text":"%sql\n/* if bike_trips_temp is not found, then you need to go back and run Tutorial 4 Working with Spark Interpreter. */\nSELECT  `Start Station Name` STARTSTATIONNAME,\n`Start Station ID` STARTSTATIONID,\n cast(`Start Station Latitude` as string) STARTSTATIONLATITUDE,\n cast(`Start Station Longitude` as string) STARTSTATIONLONGITUDE,\n`End Station ID` ENDSTATIONID,\n`End Station Name` ENDSTATIONNAME,\n cast(`End Station Latitude` as string) ENDSTATIONLATITUDE,\n cast(`End Station Longitude` as string) ENDSTATIONLONGITUDE,\n`Start Time` STARTTIME,\n`Stop Time` STOPTIME,\n cast(`Start Time` as date) STARTDATE,\n cast(date_format(`Start Time`,\"H\") as integer) STARTHOUR,\n date_format(date,\"E\") STARTDAY_OF_WEEK,\n IF(isnull(h.value), 'Not_Holiday', 'Holiday') HOLIDAY,\n IF(isnull(h.value) and date_format(date,\"E\") in (\"Mon\",'Tue','Wed','Thu','Fri'), 'Workday', 'Not_Workday') WORKDAY,\n`Trip Duration` TRIPDURATION,\n`Bike ID` BIKEID,\n`User Type` USERTYPE,\n`Birth Year` BIRTHYEAR,\n 2017-`Birth Year` RIDERAGE,\n`Gender` GENDER_CODE,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end GENDER ,\n w.AWND AVERAGEWIND, \n w.PRCP PRECIPITATION, \n w.SNOW SNOW, \n w.SNWD SNOW_ON_GROUND, \n w.TMAX MAXTEMPERATURE, \n w.TMIN MINTEMPERATURE\nFROM weather_temp w\n  LEFT OUTER JOIN holidays_temp h\n    ON (w.date = h.value),\n  bike_trips_temp t\nWHERE to_date(w.date) = to_date(t.`Start Time`)\nAND w.station='USW00094728'\nlimit 20","dateUpdated":"2018-03-06T19:41:15+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275488_72959340","id":"20171011-183404_1003517491","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1802"},{"title":"Create a permanent table of bike trips joined with weather and calendar (will not have output)","text":"%sql\ncreate table bike_trips_weather_parquet\nstored as parquet\nSELECT  `Start Station Name` STARTSTATIONNAME,\n`Start Station ID` STARTSTATIONID,\n cast(`Start Station Latitude` as string) STARTSTATIONLATITUDE,\n cast(`Start Station Longitude` as string) STARTSTATIONLONGITUDE,\n`End Station ID` ENDSTATIONID,\n`End Station Name` ENDSTATIONNAME,\n cast(`End Station Latitude` as string) ENDSTATIONLATITUDE,\n cast(`End Station Longitude` as string) ENDSTATIONLONGITUDE,\n`Start Time` STARTTIME,\n`Stop Time` STOPTIME,\n cast(`Start Time` as date) STARTDATE,\n cast(date_format(`Start Time`,\"H\") as integer) STARTHOUR,\n date_format(date,\"E\") STARTDAY_OF_WEEK,\n IF(isnull(h.value), 'Not_Holiday', 'Holiday') HOLIDAY,\n IF(isnull(h.value) and date_format(date,\"E\") in (\"Mon\",'Tue','Wed','Thu','Fri'), 'Workday', 'Not_Workday') WORKDAY,\n`Trip Duration` TRIPDURATION,\n`Bike ID` BIKEID,\n`User Type` USERTYPE,\n`Birth Year` BIRTHYEAR,\n 2017-`Birth Year` RIDERAGE,\n`Gender` GENDER_CODE,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end GENDER ,\n w.AWND AVERAGEWIND, \n w.PRCP PRECIPITATION, \n w.SNOW SNOW, \n w.SNWD SNOW_ON_GROUND, \n w.TMAX MAXTEMPERATURE, \n w.TMIN MINTEMPERATURE\nFROM weather_temp w\n  LEFT OUTER JOIN holidays_temp h\n    ON (w.date = h.value),\n  bike_trips_temp t\nWHERE to_date(w.date) = to_date(t.`Start Time`)\nAND w.station='USW00094728'","dateUpdated":"2018-03-07T02:58:26+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275488_72959340","id":"20170928-202705_1728257996","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1803","user":"anonymous","dateFinished":"2018-03-07T02:58:58+0000","dateStarted":"2018-03-07T02:58:26+0000"},{"text":"%md\n# Querying the combined bike trip, weather, and calendar information\n\nNow we can show some examples of querying our combined table. ","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Querying the combined bike trip, weather, and calendar information</h1>\n<p>Now we can show some examples of querying our combined table.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275489_72574591","id":"20170417-093337_291620887","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1804"},{"title":"Trips by type of day and weather","text":"%sql\nselect cast(starttime as date) day, workday, precipitation, count(*)\nfrom bike_trips_weather_parquet\ngroup by cast(starttime as date), workday, precipitation\norder by day","dateUpdated":"2018-03-06T19:41:15+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":314,"optionOpen":false,"keys":[{"name":"day","index":0,"aggr":"sum"}],"values":[{"name":"count(1)","index":2,"aggr":"sum"}],"groups":[{"name":"workday","index":1,"aggr":"sum"}],"scatter":{"xAxis":{"name":"dayofmonth","index":0,"aggr":"sum"},"yAxis":{"name":"_c1","index":1,"aggr":"sum"}},"forceY":true,"setting":{"lineChart":{"lineWithFocus":false,"forceY":false},"multiBarChart":{"stacked":false},"stackedAreaChart":{"style":"expand"}},"commonSetting":{}},"helium":{}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275489_72574591","id":"20170417-095623_1767722062","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1805"},{"title":"Workday Bike Trips by Hour","text":"%sql\nselect startdate,  starthour, count(*)\nfrom (select starthour,\n startday_of_week,\n startdate\nfrom bike_trips_weather_parquet\nwhere workday=\"Workday\"\nand (gender=\"${gender=Male,Male|Female|unknown}\" )) bike_times\ngroup by startdate,  starthour","dateUpdated":"2018-03-07T02:59:10+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"lineChart","height":694.467,"optionOpen":false,"keys":[{"name":"starthour","index":1,"aggr":"sum"}],"values":[{"name":"count(1)","index":2,"aggr":"sum"}],"groups":[{"name":"startdate","index":0,"aggr":"sum"}],"scatter":{"xAxis":{"name":"dayofweek","index":0,"aggr":"sum"},"yAxis":{"name":"hour","index":1,"aggr":"sum"}},"forceY":true,"lineWithFocus":false,"setting":{"lineChart":{}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{"gender":"Male"},"forms":{"gender":{"name":"gender","defaultValue":"Male","options":[{"value":"Male","$$hashKey":"object:3430"},{"value":"Female","$$hashKey":"object:3431"},{"value":"unknown","$$hashKey":"object:3432"}],"hidden":false,"$$hashKey":"object:3424"}}},"apps":[],"jobName":"paragraph_1520365275489_72574591","id":"20170414-134451_506665191","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1806","user":"anonymous","dateFinished":"2018-03-07T02:59:12+0000","dateStarted":"2018-03-07T02:59:10+0000"},{"text":"%md\n# Next Steps\n\nSo far in the journey, we have downloaded Citi Bike data and stored it into the Object Store.  Then, we configured Spark to be able to work with CSV files.  Then, we read in the data and defined a Spark SQL temporary table with it.  \n\nIn this tutorial, we added some additional datasets.  We showed how to download daily weather data and use it as a Spark table.  And we showed how to create a simple holiday table.  Then we combined the bike trips, weather, and holiday data into a single table and saved it as a permanent hive table called bike_trips_weather_parquet.\n\nTo continue, proceed to the next tutorial where we will show you how you can connect Oracle Data Visualization Desktop to BDCS-CE and begin to visualize our combined bike_trips_weather_parquet dataset.\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Next Steps</h1>\n<p>So far in the journey, we have downloaded Citi Bike data and stored it into the Object Store. Then, we configured Spark to be able to work with CSV files. Then, we read in the data and defined a Spark SQL temporary table with it. </p>\n<p>In this tutorial, we added some additional datasets. We showed how to download daily weather data and use it as a Spark table. And we showed how to create a simple holiday table. Then we combined the bike trips, weather, and holiday data into a single table and saved it as a permanent hive table called bike_trips_weather_parquet.</p>\n<p>To continue, proceed to the next tutorial where we will show you how you can connect Oracle Data Visualization Desktop to BDCS-CE and begin to visualize our combined bike_trips_weather_parquet dataset.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275490_73728838","id":"20170417-103925_248941849","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1807"},{"text":"%md\n### Change Log\nMarch 6, 2018 - Tested with OCI and 18.1.4\nOctober 13, 2017 - Created and tested with 17.3.5.","dateUpdated":"2018-03-07T02:59:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>March 6, 2018 - Tested with OCI and 18.1.4<br/>October 13, 2017 - Created and tested with 17.3.5.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1520365275490_73728838","id":"20170614-163657_1564876178","dateCreated":"2018-03-06T19:41:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1808","user":"anonymous","dateFinished":"2018-03-07T02:59:50+0000","dateStarted":"2018-03-07T02:59:50+0000"},{"text":"%md\n","dateUpdated":"2018-03-06T19:41:15+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520365275490_73728838","id":"20170728-131606_1414555962","dateCreated":"2018-03-06T19:41:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1809"}],"name":"Journeys/New Data Lake/Tutorial 4b Adding more datasets","id":"2D9BRK9Q5","angularObjects":{"2D9PWB7FU:shared_process":[],"2DAGTK881:shared_process":[],"2D9UGKJ9F:shared_process":[],"2DAURHBVK:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2DA57YKUM:shared_process":[],"2DAMRQE9G:shared_process":[],"2D9GNGXVV:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}